---
title: "Predicting Diabetes in Pima Indian Patients from Medical Predictors"
output:
  pdf_document: default
  html_notebook: default
---

```{r}
# Loading packages
library(caret)
library(mice)
library(e1071)
library(rattle)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
```

This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.

```{r}
# Read in the data
full_dataset = read.csv("./diabetes.csv")
full_dataset$Outcome = as.factor(full_dataset$Outcome)

head(full_dataset)
str(full_dataset)
nrow(full_dataset)
```

The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.

The dataset contains 768 patient samples.

```{r}
# Five-Number summaries of diagnostic predictors
apply(full_dataset[, -9], 2, summary)
```

```{r}
# Data cleaning stage
pMiss <- function(x){sum(x == 0)/length(x)*100}
apply(full_dataset[, -c(1,9)], 2, pMiss)
```

We can see from this that SkinThickness and Insulin have about 30% and 49% of their data missing, respectively. A safe maximum threshold for missing data is 5% of the total for large datasets. As such, we will discard the two predictors SkinThickness and Insulin as they have more than 5% of their data points missing.

As for Pregnancies and Outcome, they will not be subject to the same criteria as it is completely reasonable for Pregnancies to be 0 and Outcome is a binary response variables which takes values 0 and 1.

```{r}
# Dropping prediction features that have greater than 5% of their data points missing
dataset = full_dataset
dataset$SkinThickness = NULL
dataset$Insulin = NULL

# Replacing 0's with NA's in the remaining predictors that have missing values
dataset[, -c(1, 7)][dataset[, -c(1, 7)] == 0] <- NA

tempData = mice(dataset, m=20, maxit=50, meth='pmm', seed=500)
tempData$method
  
completedData = complete(tempData, 'long')
a = aggregate(completedData[,4:6] , by = list(completedData$.id), FUN = mean)

dataset[, 2:4] = a[, 2:4]
dataset
#md.pattern(dataset)
```


```{r}
barplot(prop.table(table(dataset$Outcome)), xlab = "Diabetes Diagnosis", ylab = "Frequency Density", main = "Ratios of Positive and Negative Diabetes Diagnoses in Pima Indian Patients")
```

```{r}
pregnancy_patients = dataset[dataset$Pregnancies != 0, ]
no_pregnancy_patients = dataset[dataset$Pregnancies == 0, ]

nrow(pregnancy_patients)
nrow(no_pregnancy_patients)
barplot(prop.table(table(pregnancy_patients$Outcome)), xlab = "Diabetes Diagnosis", ylab = "Frequency Density", main = "Ratio of Diabetes Diagnoses in Pima Indian Patients that have been pregnant >=1 times")
barplot(prop.table(table(no_pregnancy_patients$Outcome)), xlab = "Diabetes Diagnosis", ylab = "Frequency Density", main = "Ratio of Diabetes Diagnoses in Pima Indian Patients that were never pregnant")

```

```{r}
# Correlation matrix of predictor variables
library(corrplot)
diabetes.cor = cor(dataset[, -7])
corrplot(diabetes.cor)
```

```{r}
# Plotting Age vs Pregnancies
plot(Age ~ Pregnancies, data = dataset, main = "Age vs Pregnancies in Patients of Pima Indian Heritage")
cor(dataset$Age, dataset$Pregnancies)
```

```{r}
# Plotting BMI vs Glucose
plot(BMI ~ Glucose, data = dataset, main = "BMI vs Glucose in Patients of Pima Indian Heritage")
```


```{r}
hist(dataset$Pregnancies, main = "Historgram of Pregnancies")

hist(dataset$Glucose, main = "Histogram of Glucose")

hist(dataset$DiabetesPedigreeFunction, main = "Histogram of Diabetes Pedigree Function")
```

```{r}
# Principal Component Analysis
pcs = prcomp(dataset[,-7], scale = TRUE)
pcs
summary(pcs)
screeplot(pcs, type = "lines", main = "Variance explained by PC")
```

```{r}
plot(pcs$x[,1:2], main = "Biplot of Diabetes Data", xlab = "PC 1", ylab = "PC 2", col = dataset$Outcome)

pairs(pcs$x[, 1:3], col = dataset$Outcome, main = "Pairs Plot of First Three PCs")
```

```{r}
# Creating the training and test sets
set.seed(123)
split = createDataPartition(dataset$Outcome, p=0.8, list=FALSE)
train = dataset[split,]
test  = dataset[-split,]
```

```{r}
barplot(prop.table(table(train$Outcome)), xlab = "Diabetes Diagnosis", ylab = "Frequency Density", main = "Ratio of Diabetes Diagnoses in Training Set")

barplot(prop.table(table(test$Outcome)), xlab = "Diabetes Diagnosis", ylab = "Frequency Density", main = "Ratio of Diabetes Diagnoses in Testing Set")
```


```{r}
# Applying Decision Tree Models on Training set
set.seed(4)
tree = rpart(Outcome~., data = train, method = 'class')
#rpart.plot(tree, extra = 106)
fancyRpartPlot(tree)
summary(tree)
```

```{r}
# Cross-Validation to find the complexity parameter that gives the optimal tree
printcp(tree)
plotcp(tree)
min.cp = tree$cptable[which.min(tree$cptable[,"xerror"]), "CP"]
min.cp
```

```{r}
# Pruning our tree to create the optimal decision tree

ptree = prune(tree, cp = min.cp)
fancyRpartPlot(ptree, uniform = TRUE, main = "Pruned Classification Tree")
```

```{r}
# Testing Error
predict_unseen = predict(ptree, test, type='class')
ptree.error_rate = sum(predict_unseen != test$Outcome)/nrow(test)
ptree.error_rate
```

```{r}
# Applying Support Vector Machines Classification
#-----------------------------

set.seed(3)
# Feature scaling
scaled_train = train
scaled_test = test
scaled_train[,-7] = scale(scaled_train[,-7])
scaled_test[,-7]  = scale(scaled_test[,-7])

# Do PCA for creating two factors
pca = preProcess(scaled_train[,-7], method='pca')

scaled_train = predict(pca, scaled_train)   # column orders change. The DV becomes the first variable
scaled_test =  predict(pca, scaled_test)

# Just rearranging the columns
#scaled_train = scaled_train[,c(2,3,1)]
#scaled_test  = scaled_test[,c(2,3,1)]

# Create a logistic rgression model on the reduced data
#modSVM = svm(Outcome~.,data=scaled_train, type='C-classification', kernel='linear')
tune.out = tune(svm, Outcome~.,data=scaled_train, type='C-classification', kernel='linear',
                ranges =list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
modSVM = tune.out$best.model
modSVM$cost

# Predict the outcomes using the model
y_pred = predict(modSVM, scaled_test[,-1])


# Evaluate the model
confusionMatrix(y_pred, scaled_test[,1])

# Testing Error
sum(y_pred != scaled_test$Outcome)/nrow(scaled_test)

#plot(modSVM, scaled_train, PC2 ~ PC1)
```

```{r}
# Visualize the decision boundaries for training set

set.seed(3)
# Feature scaling
scaled_train = train
scaled_test = test
scaled_train[,-7] = scale(scaled_train[,-7])
scaled_test[,-7]  = scale(scaled_test[,-7])

# Do PCA for creating two factors
pca = preProcess(scaled_train[,-7], method='pca', pcaComp = 2)

scaled_train = predict(pca, scaled_train)   # column orders change. The DV becomes the first variable
scaled_test =  predict(pca, scaled_test)

# Just rearranging the columns
scaled_train = scaled_train[,c(2,3,1)]
scaled_test  = scaled_test[,c(2,3,1)]

# Create a logistic rgression model on the reduced data
#modSVM = svm(Outcome~.,data=scaled_train, type='C-classification', kernel='linear')
tune.out = tune(svm, Outcome~.,data=scaled_train, type='C-classification', kernel='linear',
                ranges =list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
modSVM = tune.out$best.model

# Predict the outcomes using the model
y_pred = predict(modSVM, scaled_test[,-3])

set = scaled_train

X1 = seq(from=min(set[,1])-1, to=max(set[,1]+1), by=0.02)
X2 = seq(from=min(set[,2])-1, to=max(set[,2]+1), by=0.02)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
y_grid = predict(modSVM, grid_set)

plot(set[,-3],
     main = 'SVM after Principal Component Analysis',
     xlab = 'PC1', ylab = 'PC2',
     xlim = range(X1), ylim = range(X2))

#contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)   # this is optional

points(grid_set, pch='.',col=ifelse(y_grid==2,'deepskyblue',ifelse(y_grid==1,'springgreen3','tomato')))
points(set, pch=21, bg=ifelse(set[,3]==2,'blue3', ifelse(set[,3]==1, 'green4','red3')))




# Visualize the decision boundaries for test set
# set = scaled_test
# 
# X1 = seq(from=min(set[,1])-1, to=max(set[,1]+1), by=0.02)
# X2 = seq(from=min(set[,2])-1, to=max(set[,2]+1), by=0.02)
# grid_set = expand.grid(X1, X2)
# colnames(grid_set) = c('PC1', 'PC2')
# y_grid = predict(modSVM, grid_set)
# 
# plot(set[,-3],
#      main = 'SVM after Principal Component Analysis',
#      xlab = 'PC1', ylab = 'PC2',
#      xlim = range(X1), ylim = range(X2))
# 
# #contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)   # this is optional
# 
# points(grid_set, pch='.',col=ifelse(y_grid==2,'deepskyblue',ifelse(y_grid==1,'springgreen3','tomato')))
# points(set, pch=21, bg=ifelse(set[,3]==2,'blue3', ifelse(set[,3]==1, 'green4','red3')))
```

