---
title: 'Exploratory Data Ananlysis: Low-Income Energy Affordability Data'
author: "Eric Scheier"
date: "3/19/2020"
output:
  md_document:
    variant: markdown_github
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readxl)
```
# Introduction

```{r params}
acs_date <- 2016
youngest_building <- acs_date - 1
oldest_building <- 1900
max_units <- 500 # 1 NYC block is 5 acres, assume 100 units/acre
```


This is an exploratory data analysis of the Low Income Energy Affordability Data [LEAD](https://catalog.data.gov/dataset/low-income-energy-affordability-data-lead-tool) from the Department of Energy (DOE). This dataset represents an estimate of the monthly energy bills and average incomes of households in the united states, segmented by the following characteristics:

+ Year of building first construction
+ Number of units in the building
+ Primary heating fuel type
+ Whether the residents own or rent the unit
+ Household income relative to Area Median Income or Federal Poverty Level
+ State
+ County, City, or Census Tract

For this project, I will use the data which displays the results by census tract in terms of Area Median Income for the state of North Carolina.

# Acquiring Data

```{r cache=TRUE}
base_url <- "https://openei.org/doe-opendata/dataset/9dcd443b-c0e5-4d4a-b764-5a8ff0c2c92b/resource/831ac481-1a60-4f87-a887-15b310ffff53/download/"


file_name <- "ami68tractshnc"
data_url <- paste0(base_url,file_name,".csv")
desired_name <- paste0(file_name,".csv")
desired_path <- file.path(desired_name)

if (!file.exists(desired_path)){
  download.file(data_url,desired_path)
}
```

A full data dictionary is available. It is downloaded and loaded into constituent dataframes below.

```{r}
# https://readxl.tidyverse.org/articles/articles/readxl-workflows.html

read_then_csv <- function(sheet, path) {
  pathbase <- path %>%
    basename() %>%
    tools::file_path_sans_ext()
  path %>%
    read_excel(sheet = sheet, col_names = FALSE, col_types = "text") %>% 
    write_csv(paste0(sheet, ".csv"))
}

url <- "https://openei.org/doe-opendata/dataset/9dcd443b-c0e5-4d4a-b764-5a8ff0c2c92b/resource/51a2cd49-fd61-4842-82e2-2f90ffec7e42/download/datadictionary.xlsx"

if(!file.exists("Data Dictionary.csv")){
  temp <- tempfile()
  download.file(url,temp,mode="wb")
  path <- temp
  path %>%
    excel_sheets() %>%
    set_names() %>% 
    map(read_then_csv, path = path)
}

data_dict <- read_csv("Data Dictionary.csv")

ybl_dict <- data_dict[1:7,1:2]
ybl_dict[1,2] <- data_dict[1,3]
names(ybl_dict) <- as.matrix(ybl_dict[1, ])
ybl_dict <- ybl_dict[-1, ]

bld_dict <- data_dict[9:18,1:2]
bld_dict[1,2] <- data_dict[9,3]
names(bld_dict) <- as.matrix(bld_dict[1, ])
bld_dict <- bld_dict[-1, ]

hfl_dict <- data_dict[20:29,1:2]
hfl_dict[1,2] <- data_dict[20,3]
names(hfl_dict) <- as.matrix(hfl_dict[1, ])
hfl_dict <- hfl_dict[-1, ]

burden_dict <- data_dict[1:9,7:8]
names(burden_dict) <- c("Variable", "Description")
burden_dict <- rbind(burden_dict, 
                     names(hfl_dict), 
                     names(bld_dict), 
                     names(ybl_dict))
burden_dict
```


```{r}
data <- read_csv(desired_path)

summary(data)
```

# Data Munging

Munging Steps:

+ Remove rows where `UNITS<1`.
+ Seperate the `AMI68` column into `occupancy_type` and `income_bracket` columns
+ Create `min_age` from `YBL INDEX`.
+ Create `min_units` from `BLD INDEX`.
+ Create `detached` from `BLD INDEX`.
+ Create the Energy Expenditures Indicator `mean_energy_cost`.
+ Create the Energy Burden Indicator `mean_energy_burden`.

## Remove Fractional Units

The estimation procedure used by the DOE results in an estimated number of occupied housing units meeting the subset characteristics (`UNITS`) and displays the number of American Community Survey responses that contribute to the estimate of energy expenditures (`COUNT`). We first remove any categories that have fewer than 1 unit represented, since this is not physically possible.

This results in removing `r 100*sum(data$UNITS<1)/length(data$UNITS)`% of the available rows (gross: `r sum(data$UNITS<1)` rows of `r length(data$UNITS)`). This is a total of `r sum(data$UNITS[data$UNITS<1])` housing units, or `r 100*sum(data$UNITS[data$UNITS<1])/sum(data$UNITS)`% of the estimated total `r sum(data$UNITS)` units in the state.

```{r}
#Remove rows where `UNITS<1`.

data <- data[data$UNITS>=1,]
```

## Break Out Ownership & Income Bracket

The data combines the unit's ownership status (`OWNER` vs. `RENTER`) and income bracket as a fraction of Area Median Income (`0-30%`, `30-60%`, `60-80%`, `80-100%`, or `100%+`) into the same column (e.g. `r data$AMI68[1]`). This `AMI68` column needs to be seperated for meaningful analysis. These categorical variables are saved as factors.

```{r}
#Seperate the `AMI68` column into `occupancy_type` and `income_bracket` columns

data <- data %>% 
  separate(col="AMI68",
           into=c("occupancy_type", "income_bracket"), 
           sep = " ", 
           remove = FALSE, 
           convert = FALSE,
           extra = "warn", 
           fill = "warn")

data$occupancy_type <- as.factor(data$occupancy_type)
data$income_bracket <- as.factor(data$income_bracket)
```

## Create Meaningful Indicators from Indices

The `YBL INDEX` and `BLD INDEX` columns need some further treatment. `YBL INDEX` represents the year the building was first constructed, but is an index seperated into 10-20 year increments dating back to 1940. 

```{r}
ybl_dict
```


Since these indeces represent different possible ages and the increments are not uniform, I will add a numerical indicator (`min_age`) to represent the youngest age the building could possibly be based on its category. Thus, a building in the `2010+` range must be at least 0 years old (this data was collected in `r acs_date`), in the `1980-99` range at least `r acs_date-1980` years old, in the `BEFORE 1940` range at least `r acs_date-1940`, etc. I choose youngest rather than oldest age because it avoids the requirement to make an assumption about the oldest age of buildings built before 1940.

For simplicity, I assume that the youngest building is 1 year old.

```{r}
#Create `min_age` from `YBL INDEX`.

ybl_ranges <- str_extract_all(ybl_dict$`Year of building first construction`, "[0-9]+", simplify=TRUE)
ybl_ranges <- apply(ybl_ranges, c(1,2), as.numeric)
ybl_ranges[1,2] <- youngest_building
ybl_ranges[6,2] <- ybl_ranges[6,1]
ybl_ranges[6,1] <- oldest_building
ybl_ranges[2:5,2] <- floor(ybl_ranges[2:5,1]/100)*100 + ybl_ranges[2:5,2]

ybl_ranges <- data.frame(ybl_ranges)
names(ybl_ranges) <- c("min_year", "max_year")
ybl_ranges$min_age <- acs_date - ybl_ranges$max_year
ybl_ranges$max_age <- acs_date - ybl_ranges$min_year
ybl_dict <- cbind(ybl_dict, ybl_ranges)
ybl_dict$`YBL INDEX` <- as.factor(ybl_dict$`YBL INDEX`)


ybl_dict <- rename(ybl_dict,
                   year_constructed=`Year of building first construction`)

ybl_dict$year_constructed <- as.factor(ybl_dict$year_constructed)

data$`YBL INDEX` <- as.factor(data$`YBL INDEX`)
data <- merge(data, ybl_dict[c("YBL INDEX",
                               "min_age",
                               "year_constructed")], 
              by = "YBL INDEX", 
              all.x = TRUE)
```

Similar to building age, the variable `BLD INDEX` represents a non-uniformly distributed set of buckets for the range of `number of units in the building`, as well as whether single unit households are attached or detached from neighboring households. I will extract the minimum number of units from the range, and whether the building is detached.

Those households labeled `OTHER UNIT` will be given values of `NA` for this characteristic.

```{r}
#Create `min_units` from `BLD INDEX` (and `max_units`).
#Create `detached` from `BLD INDEX`.

bld_ranges <- str_extract_all(bld_dict$`Number of units in the building`, "[0-9]+", simplify=TRUE)

bld_ranges <- apply(bld_ranges, c(1,2), as.numeric)
bld_ranges[1:3,2] <- bld_ranges[1:3,1]
bld_ranges[8,2] <- max_units

bld_ranges <- data.frame(bld_ranges)
names(bld_ranges) <- c("min_units", "max_units")

bld_ranges$detached <- as.factor(c(1,rep(0,nrow(bld_ranges)-2),NA))

bld_dict <- cbind(bld_dict, bld_ranges)
bld_dict$`BLD INDEX` <- as.factor(bld_dict$`BLD INDEX`)

bld_dict <- rename(bld_dict,
                   number_of_units=`Number of units in the building`)

bld_dict$number_of_units <- as.factor(bld_dict$number_of_units)

data$`BLD INDEX` <- as.factor(data$`BLD INDEX`)
data <- merge(data, bld_dict[c("BLD INDEX",
                               "min_units",
                               "detached",
                               "number_of_units")], 
              by = "BLD INDEX", 
              all.x = TRUE)
```

## Assign Primary Heating Fuel Type

```{r}
hfl_dict <- rename(hfl_dict,
               primary_heating_fuel=`Primary heating fuel type`)

hfl_dict$primary_heating_fuel <- as.factor(hfl_dict$primary_heating_fuel)

data <- merge(data, hfl_dict[c("HFL INDEX","primary_heating_fuel")], 
              by = "HFL INDEX", 
              all.x = TRUE)
```



## Create the Energy Burden Indicators

Creating the final metric of average energy burden for each cohort is as simple as adding up the montly expenditures on electricity (`ELEP CAL`), natural gas (`GASP CAL`), and other fuels (`FULP`), and dividing this by the cohort's average monthly income (`HINCP / 12.0`).

```{r}
# Create the Energy Expenditures Indicator `mean_energy_cost`.

data$mean_energy_cost <- data$`ELEP CAL` + data$`GASP CAL` + data$FULP

# Create the Energy Burden Indicator `mean_energy_burden`.

data$mean_energy_burden <- data$mean_energy_cost / (data$HINCP/12.0)

weird_rows <- data$HINCP<=0 | data$mean_energy_cost<=0 | data$mean_energy_burden>1
weird_data <- data[weird_rows,]
data <- data[!weird_rows,]

weird_rate <- nrow(weird_data)/(nrow(data)+nrow(weird_data))
weird_unit_rate <- sum(weird_data$UNITS)/(sum(data$UNITS)+sum(weird_data$UNITS))
```

I have seperated any cohorts with incomes or energy costs less than or equal to $0, or energy costs greater than income into another dataset for analysis. This represents approximately `r round(100*weird_unit_rate,0)`% of the housing units and `r round(100*weird_rate,0)`% of the examined cohorts, so it will be important to make sure that this subset does not contain systematic bias.

## Clean-up

+ rename variables for convenience
+ keep only what we need

Select the columns I want:

```{r}
data <- select(data,
               `GEO ID`,
               `PUMA10`,
               `FMR`,
               `occupancy_type`,
               `income_bracket`,
               `primary_heating_fuel`,
               `number_of_units`,
               `year_constructed`,
               `UNITS`, 
               `HINCP`, 
               `ELEP CAL`, 
               `GASP CAL`, 
               `FULP`, 
               `COUNT`, 
               `min_age`, 
               `min_units`, 
               `detached`,
               `mean_energy_cost`,
               `mean_energy_burden`)
```

Rename columns to remove spaces:

```{r}
data <- rename(data,
               geo_id=`GEO ID`,
               puma10_code=`PUMA10`,
               fmr_code=`FMR`,
               households=`UNITS`, 
               acs_responses=`COUNT`,
               annual_income=`HINCP`,
               electricity_spend=`ELEP CAL`, 
               gas_spend=`GASP CAL`, 
               other_spend=`FULP`)
```

Decompose the geo_id into state, county, and tract codes for interpretibility.

```{r}
data <- separate(data,
                 col=geo_id,
                 into=c("state_id","county_id","tract_id"),
                 sep=c(2,5), 
                 remove=FALSE, 
                 convert=TRUE)
```


```{r}
write_csv(data,"clean_lead.csv")
```


# Questions:

+ How many ACS survey responses inform each segment? (`COUNT` vs `UNITS`)
+ Are there any trends in the energy burden based on age, units/building, home ownership, home attachment, ?
+ Perform a principal component analysis
+ Does `YBL INDEX` or `min_age` better explain the energy burden variance?
+ Does `BLD INDEX` or `min_units` better explain the energy burden variance?

```{r}
data <- read_csv("clean_lead.csv",
                 col_types=cols(
                   geo_id = col_factor(),
                   state_id = col_factor(),
                   county_id = col_factor(),
                   tract_id = col_factor(),
                   puma10_code = col_factor(),
                   fmr_code = col_factor(),
                   occupancy_type = col_factor(),
                   income_bracket = col_factor(),
                   primary_heating_fuel = col_factor(),
                   number_of_units = col_factor(),
                   year_constructed = col_factor(),
                   households = col_double(),
                   annual_income = col_double(),
                   electricity_spend = col_double(),
                   gas_spend = col_double(),
                   other_spend = col_double(),
                   acs_responses = col_double(),
                   min_age = col_double(),
                   min_units = col_double(),
                   detached = col_factor(),
                   mean_energy_cost = col_double(),
                   mean_energy_burden = col_double()
                   ))
```

```{r}
summary(lm(formula = mean_energy_cost ~ annual_income,
   data=data))
```

```{r}
summary(lm(formula= mean_energy_cost ~ income_bracket +
             occupancy_type + 
             primary_heating_fuel + 
             number_of_units + 
             year_constructed,
   data=data))
```

```{r}
summary(lm(formula= mean_energy_cost ~ annual_income + 
             min_units + 
             occupancy_type + 
             detached + 
             primary_heating_fuel + 
             min_age,
   data=data))
```

```{r}
summary(lm(formula= mean_energy_burden ~ annual_income + 
             min_units + 
             occupancy_type + 
             detached + 
             primary_heating_fuel + 
             min_age,
   data=data))
```

```{r}
summary(lm(formula= mean_energy_burden ~ income_bracket +
             occupancy_type + 
             primary_heating_fuel + 
             number_of_units + 
             year_constructed,
   data=data))
```


# EDA techniques to integrate

2. Print the top 10 AQI values and their corresponding sites and dates

```{r}
data %>% 
  arrange(desc(mean_energy_burden)) %>% 
  select(mean_energy_burden, 
         annual_income, 
         mean_energy_cost, 
         income_bracket, 
         households,
         number_of_units) %>% 
  slice(1:10)
```


```{r}
data %>%
  arrange(desc(mean_energy_cost)) %>%
  select(mean_energy_cost, annual_income, mean_energy_burden) %>%
  slice(1:20)
```

```{r}
ggplot(data=data,
       aes(x=mean_energy_burden,y=households)) + 
      geom_bar(stat="identity")
```


create a unqiue id for each site identifier

```{r eval=FALSE}
data <- mutate(data, cohort_id = paste(geo_id, , sep="_")) 
head(ozone_airq_df2$SiteID)
```

### Group_by

```{r}
group_by(ozone_airq_df2, SiteID) %>%
  filter(n() < 30)
```

```{r}
group_by(ozone_airq_df2, stcofips, dateL) %>%
  summarize(maxAQI=max(AQI))
```

```{r}
county_summary_df <- group_by(ozone_airq_df2, stcofips, dateL) %>%
  summarize(maxAQI=max(AQI),
            State_Name=first(State_Name), # We can do this because we know that there is only one state corresponding to a stcofips, i.e. counties are embedded in the state.
            County_Name=first(County_Name), # We also need these variables to carry over to the next step.
            CBSA_Name=first(CBSA_Name)) %>%
  group_by(stcofips) %>%
  summarize(AQIgt100 = sum(maxAQI>=100), 
            numDays= n(), 
            percAQIgt100 = AQIgt100/numDays, 
            State_Name=first(State_Name), 
            County_Name=first(County_Name), 
            CBSA_Name=first(CBSA_Name)
            )

county_summary_df
```

## Basic Plotting

```{r}
g1 <- ozone_airq_df2 %>% 
  filter(stcofips == "06059") %>% # Orange County
  ggplot() + 
  geom_point(aes(x=dateL, y=AQI, color=SiteID)) +
  geom_smooth(aes(x=dateL, y=AQI, color=SiteID), method="loess")+
  scale_colour_brewer(palette = "Set2") + 
  labs(x = "Month", y = "Air Quality Index")

library(plotly)
ggplotly(g1)
```

```{r}
ozone_airq_df2 %>% 
  filter(stcofips == "06059") %>% # Orange County
  ggplot() + 
  coord_polar(theta = "x")+
  geom_point(aes(x=dateL, y=AQI, color=SiteID), alpha=.5, show.legend = FALSE) +
  geom_smooth(aes(x=dateL, y=AQI, color=SiteID), se=FALSE)+
  scale_colour_brewer(palette = "Dark2") + 
  labs(x = "Month", y = "Air Quality Index")
```

## Faceting

```{r}
g1 <- ozone_airq_df2 %>% 
  filter(State_Name == "California") %>% 
  ggplot() + 
  geom_smooth(aes(x=dateL, y=AQI, color=SiteID), method="loess",  se=FALSE)+
  scale_colour_grey(end = 0)+
  facet_wrap(~stcofips)+
  labs(x = "Month", y = "Air Quality Index") + 
  theme_bw() + 
  theme(axis.text.x=element_blank(),
        legend.position="none")

 ggplotly(g1)
```

### Exercise

Facet CA counties by CBSA (i.e CBSA in rows and Counties in Columns) and produce the same graph as above.

```{r}
g1 <- ozone_airq_df2 %>% 
  filter(State_Name == "California") %>% 
  ggplot() + 
  geom_smooth(aes(x=dateL, y=AQI, color=SiteID), method="loess",  se=FALSE)+
  scale_colour_grey(end = 0)+
  facet_wrap(vars(CBSA_Name,County_Name))+
  #facet_grid(rows = vars(CBSA_Name), cols = vars(County_Name))+
  labs(x = "Month", y = "Air Quality Index") + 
  theme_bw() + 
  theme(axis.text.x=element_blank(),
        legend.position="none")

 ggplotly(g1)
```


Using facetting as above, limit the x-axis to summer months.

Thanks to (stackoverflow)[https://stackoverflow.com/a/14162999]

```{r}
g1 <- ozone_airq_df2 %>% 
  filter(State_Name == "California") %>% 
  ggplot() + 
  geom_smooth(aes(x=dateL, y=AQI, color=SiteID), method="loess",  se=FALSE)+
  xlim(as.Date(c('2017-06-21', '2017-09-21'), format="%Y-%m-%d") )+
  scale_colour_grey(end = 0)+
  facet_wrap(~stcofips)+
  labs(x = "Month", y = "Air Quality Index") + 
  theme_bw() + 
  theme(axis.text.x=element_blank(),
        legend.position="none")

 ggplotly(g1)
```

```{r}
g1 <- ozone_airq_df2 %>% 
  filter(State_Name == "California")  %>% 
  ggplot() + 
  geom_smooth(aes(x=dateL, y=AQI, group=SiteID, color=stcofips), method="loess", se=FALSE)+
  labs(x = "Month", y = "Air Quality Index") + 
  theme_bw() 

ggplotly(g1)
```

## Statistical Summaries By Group

```{r}
g1 <- ozone_airq_df2 %>% 
  filter(stcofips == "06037") %>% 
  ggplot() + 
  geom_point(aes(x=Site_Num, y=AQI), show.legend = F)+
  stat_summary(aes(x=Site_Num, y=AQI), fun.y='median', colour = "red", size = 2)+
  stat_summary(aes(x=Site_Num, y=AQI),fun.y='mean', colour = "green", size = 3, shape=3)+
  labs(x = "Site", y = "Air Quality Index", title="Los Angeles County") + 
  theme_bw() 

ggplotly(g1)
```

```{r}
g1 <- ozone_airq_df2 %>% 
  filter(stcofips == "06037") %>% 
  ggplot() + 
  geom_violin(aes(x=Site_Num, y=AQI), show.legend = F)+
  stat_summary(aes(x=Site_Num, y=AQI), fun.y='median', colour = "red", size = 2)+
  stat_summary(aes(x=Site_Num, y=AQI),fun.y='mean', size = 3, shape=3)+
  labs(x = "Site", y = "Air Quality Index", title="Los Angeles County") + 
  theme_bw() 

ggplotly(g1)
```

## Cloropleth Map

Needed to install rgdal from source


```{r}
library(tigris)
library(rgdal)

ctys_spdf <- counties(cb=TRUE) #Only generalised boundaries are requiredl
```

```{r}
names(ctys_spdf@data)
# [1] "STATEFP"  "COUNTYFP" "COUNTYNS" "AFFGEOID" "GEOID"    "NAME"     "LSAD"    
# [8] "ALAND"    "AWATER"
nrow(ctys_spdf@data)
# [1] 3233
proj4string(ctys_spdf)
# [1] "+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs"
ctys_spdf <- merge(ctys_spdf, county_summary_df, by.x="GEOID", by.y='stcofips', all.x=FALSE) #Make sure to merge with spdf, not spdf@data. Otherwise, the order is jumbled.

nrow(ctys_spdf@data)
# [1] 785

# Because the presence of 0's create a problem for quantiles (some of the quantiles are the same) let's separate them out while calculating breaks.

Qpal <- colorQuantile(
  palette = "Reds", n = 5,
  domain = ctys_spdf$percAQIgt100[ctys_spdf$percAQIgt100>0]
)


labels <- sprintf(
  "County: %s <br/> AQI>100 days: <strong>%s</strong> %%",
  paste(ctys_spdf$County_Name, ctys_spdf$State_Name, sep=","),prettyNum(ctys_spdf$percAQIgt100*100, digits=2)
) %>% lapply(htmltools::HTML)

m <-  leaflet(ctys_spdf) %>%
  addProviderTiles(providers$Stamen.TonerLines, group = "Basemap") %>%
   addProviderTiles(providers$Stamen.TonerLite, group = "Basemap") %>%
       addPolygons(color = "#CBC7C6", weight = 1, smoothFactor = 0.5,
              opacity = 1.0, fillOpacity = 0.5,
             fillColor = Qpal(ctys_spdf$percAQIgt100),
              highlightOptions = highlightOptions(color = "green", weight = 2, bringToFront = TRUE),
             label = labels,
             labelOptions = labelOptions(
               style = list("font-weight" = "normal", padding = "3px 8px"),
               textsize = "15px",
               direction = "auto"),
             group = "Counties"
             )%>%
  addLayersControl(
    overlayGroups = c("Counties", 'Basemap'),
    options = layersControlOptions(collapsed = FALSE)
      ) 

  
  m 
```