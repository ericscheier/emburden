---
title: "Utility Rate Database"
author: "Emergi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(jsonlite)

# Load the JSON file
json_file_path <- "data/usurdb.json"
json_data <- fromJSON(json_file_path)

# Select a subset of the data
json_subset <- json_data[1:1000, ]  # Adjust the range as needed

# Write the subset to a new JSON file
subset_file_path <- "data/usurdb_subset.json"
write_json(json_subset, subset_file_path, pretty = TRUE)
```


```{r}
library(jsonlite)
library(DBI)
library(RSQLite)
library(dplyr)

# Load the JSON file
json_file_path <- "data/usurdb_subset.json"
json_data <- fromJSON(json_file_path)

# Inspect the structure of the data to identify any nested lists
str(json_data)

# Flatten the JSON structure to convert nested lists into columns
json_data_flattened <- jsonlite::flatten(json_data)

# Convert the flattened JSON data to a data frame
json_data_df <- as_tibble(json_data_flattened)

# Connect to the SQLite database
con <- dbConnect(SQLite(), dbname = "data/usurdb.sqlite")

# Write the data frame to the SQLite database
dbWriteTable(con, "usurdb", json_data_df, overwrite = TRUE)

# Disconnect from the database
dbDisconnect(con)

```


```{r}
library(DBI)
library(RSQLite)
library(data.table)
library(tidyverse)

# Connect to SQLite database (it will create a new database if it doesn't exist)
con <- dbConnect(RSQLite::SQLite(), "data/usurdb.sqlite")

# Load the preprocessed CSV file into SQLite
csv_file_path <- "data/usurdb.csv"
preprocessed_data <- fread(csv_file_path)

# Write the data frame to the SQLite database
dbWriteTable(con, "usurdb", preprocessed_data, row.names = FALSE, append = TRUE)

# Disconnect from the database
dbDisconnect(con)

```

```{r}

library(DBI)
library(RSQLite)
library(tidyverse)
# Connect to the SQLite database
con <- dbConnect(RSQLite::SQLite(), "data/usurdb.sqlite")

# Retrieve the schema of the table
table_name <- "usurdb"
schema_query <- paste0("PRAGMA table_info(", table_name, ")")
schema <- dbGetQuery(con, schema_query)

# Print the schema (field names and types)
schema %>%
  select(name, type) %>%
  rename(Field = name, Type = type) %>%
  print()

```

```{r}
# Use dbplyr to connect to the database table
usurdb <- tbl(con, table_name)

# Query the first five rows using dplyr
first_five_rows <- usurdb %>%
  head(5) %>%
  collect()

# Print the first five rows
print(first_five_rows)

```

```{r}
corrupted_records <- usurdb %>% 
  filter(
    is.na(endDate) &
    is_default!="false" &
      is_default!="true" & 
      is_default!=""
  ) %>% 
  select(
    label,
    eiaid,
    name,
    is_default,
    sector
    )

corrupted_resi_records <- corrupted_records %>% 
  filter(
    sector == "Residential"
  )

corrupted_resi_records
```


```{r}
usurdb %>% 
  select(is_default) %>% collect() %>% unique()
```


```{r}
resi_usurdb <- usurdb %>% 
  filter(
    is.na(enddate) &
    sector == "Residential" &
    (is_default=="true" | is.na(is_default) | is_default=="")
  ) %>% 
  arrange(eiaid) %>% 
  collect()

print(resi_usurdb)
```


```{r}
library(DBI)
library(RSQLite)
library(dplyr)
library(dbplyr)
library(readr)
library(tidyr)

# Define the placeholder
placeholder <- "NA_PLACEHOLDER"

# Connect to the SQLite database
con <- dbConnect(RSQLite::SQLite(), "data/usurdb.sqlite")

# Use dbplyr to connect to the database table
usurdb_tbl <- tbl(con, "usurdb")

# Filter the data as per your conditions
resi_usurdb <- usurdb_tbl %>%
  filter(
    is.na(enddate) &
    sector == "Residential" &
    (is_default == "true" | is.na(is_default) | is_default == "")
  ) %>%
  arrange(eiaid) %>%
  collect()

# Convert all columns to character and replace NA values with a consistent placeholder
resi_usurdb_df <- resi_usurdb %>%
  mutate(across(everything(), ~replace_na(as.character(.), placeholder)))

# Write the filtered data to a CSV file
write_csv(resi_usurdb_df, "data/usurdb_default_resi_rates.csv")

# Read the CSV back into R with all columns as characters
resi_usurdb_from_csv <- read_csv("data/usurdb_default_resi_rates.csv", col_types = cols(.default = col_character()))

# Convert the placeholder back to NA
resi_usurdb_from_csv <- resi_usurdb_from_csv %>%
  mutate(across(everything(), ~na_if(., placeholder)))

# Trim white spaces and convert to lower case for consistent comparison
resi_usurdb_df_clean <- resi_usurdb_df %>%
  mutate(across(everything(), ~str_trim(tolower(.))))

resi_usurdb_from_csv_clean <- resi_usurdb_from_csv %>%
  mutate(across(everything(), ~str_trim(tolower(.))))

# Identify mismatched rows
mismatched_rows <- resi_usurdb_df_clean %>%
  anti_join(resi_usurdb_from_csv_clean, by = colnames(resi_usurdb_df_clean))

# Write mismatched rows to a separate CSV file
write_csv(mismatched_rows, "data/usurdb_mismatched_rows.csv")

# Filter the original data using the 'label' field
filtered_resi_usurdb <- resi_usurdb_df %>%
  anti_join(mismatched_rows, by = "label")

# Write the filtered data to another CSV file
write_csv(filtered_resi_usurdb, "data/usurdb_filtered.csv")

```

```{r}
# Read the filtered CSV back into R with all columns as characters
filtered_resi_usurdb_from_csv <- read_csv("data/usurdb_filtered.csv", col_types = cols(.default = col_character()))

# Convert the placeholder back to NA
filtered_resi_usurdb_from_csv <- filtered_resi_usurdb_from_csv %>%
  mutate(across(everything(), ~na_if(., placeholder)))

# Compare the filtered data frame to the CSV data frame
comparison_result_filtered <- all.equal(filtered_resi_usurdb, filtered_resi_usurdb_from_csv, check.attributes = FALSE)
print(comparison_result_filtered)

# Ensure the tbl is a data frame
filtered_resi_usurdb_tbl_df <- as.data.frame(filtered_resi_usurdb)

# Compare the original tbl data frame to the filtered CSV data frame
comparison_result_filtered_tbl <- all.equal(filtered_resi_usurdb_tbl_df, filtered_resi_usurdb_from_csv, check.attributes = FALSE)
print(comparison_result_filtered_tbl)

# Disconnect from the database
dbDisconnect(con)

```


```{r}
library(dplyr)

# Assuming resi_usurdb has already been filtered and arranged as follows:
resi_usurdb <- usurdb %>% 
  filter(
    is.na(enddate) &
    sector == "Residential" &
    (is_default == "true" | is.na(is_default) | is_default == "")
  ) %>% 
  arrange(eiaid)

# First step: Summarize by eiaid to get the number of records per eiaid
summary_resi_usurdb <- resi_usurdb %>%
  group_by(eiaid) %>%
  summarize(record_count = n())

# Second step: Count the frequency of these counts
count_of_counts <- summary_resi_usurdb %>%
  group_by(record_count) %>%
  summarize(eiaid_count = n()) %>%
  arrange(desc(record_count))

# Print the count of eiaid by number of records
print(count_of_counts)

```


```{r}
length(names(usurdb))
```


```{r}
resi_usurdb %>% filter(label=="5a3829955457a31d47d2dd7e")
```


```{r}
usurdb %>% 
  filter(label=="5a3829955457a31d47d2dd7e") %>% 
  select(enddate, sector, is_default) %>%
  filter(
    enddate == "<NA>"
    #sector == "Residential"#,
    # (is_default == "true" | is.na(is_default))
  )
```

